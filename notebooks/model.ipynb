{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Function to make presiction and save it to csv file in kaggle submission format\n",
    "def save_submission(model, extension=\"\", transform=None):\n",
    "    \n",
    "    if transform is None:\n",
    "        # Converting predictions into exp(x) - 1\n",
    "        pred = np.expm1(model.predict(test.drop(columns=[\"timestamp\",\"row_id\"])))\n",
    "    else:\n",
    "        pred = np.expm1(model.predict(transform(test.drop(columns=[\"timestamp\",\"row_id\"]))))\n",
    "        \n",
    "    filename = time.strftime(\"%y-%m-%d-%H%M%S\") + extension +\".csv\"\n",
    "\n",
    "    # Saving predictions to csv file\n",
    "    pd.DataFrame(pred, columns=[\"meter_reading\"]).rename_axis(\"row_id\").to_csv(filename)\n",
    "    \n",
    "    #converts the csv file to 7z to reduce size\n",
    "    !p7zip $filename >> /dev/null\n",
    "    print(\"{} saved!\".format(filename))\n",
    "\n",
    "# save model to disk in pickle format\n",
    "def save_model(model, name=\"model.pkl\"):\n",
    "    with open(\"../models/\" + name, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(\"{} saved to disk!\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_featurized.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>DT_M</th>\n",
       "      <th>DT_W</th>\n",
       "      <th>DT_D</th>\n",
       "      <th>DT_hour</th>\n",
       "      <th>DT_day_week</th>\n",
       "      <th>DT_day_month</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>23.3036</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>50623</td>\n",
       "      <td>-999</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.3746</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5374</td>\n",
       "      <td>-999</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5374</td>\n",
       "      <td>-999</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>175.1840</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>97532</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>91.2653</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>81580</td>\n",
       "      <td>1913</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811273</th>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>8.7500</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>366</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19619</td>\n",
       "      <td>1914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811274</th>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>4.8250</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>366</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4298</td>\n",
       "      <td>-999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811275</th>\n",
       "      <td>1446</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>366</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11265</td>\n",
       "      <td>1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811276</th>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>159.5750</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>366</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>29775</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811277</th>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>2.8500</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>366</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>92271</td>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19811278 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          building_id  meter           timestamp  meter_reading  DT_M  DT_W  \\\n",
       "0                 105      0 2016-01-01 00:00:00        23.3036     1    53   \n",
       "1                 106      0 2016-01-01 00:00:00         0.3746     1    53   \n",
       "2                 106      3 2016-01-01 00:00:00         0.0000     1    53   \n",
       "3                 107      0 2016-01-01 00:00:00       175.1840     1    53   \n",
       "4                 108      0 2016-01-01 00:00:00        91.2653     1    53   \n",
       "...               ...    ...                 ...            ...   ...   ...   \n",
       "19811273         1444      0 2016-12-31 23:00:00         8.7500    12    52   \n",
       "19811274         1445      0 2016-12-31 23:00:00         4.8250    12    52   \n",
       "19811275         1446      0 2016-12-31 23:00:00         0.0000    12    52   \n",
       "19811276         1447      0 2016-12-31 23:00:00       159.5750    12    52   \n",
       "19811277         1448      0 2016-12-31 23:00:00         2.8500    12    52   \n",
       "\n",
       "          DT_D  DT_hour  DT_day_week  DT_day_month  ...  primary_use  \\\n",
       "0            1        0            4             1  ...            0   \n",
       "1            1        0            4             1  ...            0   \n",
       "2            1        0            4             1  ...            0   \n",
       "3            1        0            4             1  ...            0   \n",
       "4            1        0            4             1  ...            0   \n",
       "...        ...      ...          ...           ...  ...          ...   \n",
       "19811273   366       23            5            31  ...            1   \n",
       "19811274   366       23            5            31  ...            0   \n",
       "19811275   366       23            5            31  ...            1   \n",
       "19811276   366       23            5            31  ...           10   \n",
       "19811277   366       23            5            31  ...           12   \n",
       "\n",
       "          square_feet  year_built  air_temperature  cloud_coverage  \\\n",
       "0               50623        -999              3.8             NaN   \n",
       "1                5374        -999              3.8             NaN   \n",
       "2                5374        -999              3.8             NaN   \n",
       "3               97532        2005              3.8             NaN   \n",
       "4               81580        1913              3.8             NaN   \n",
       "...               ...         ...              ...             ...   \n",
       "19811273        19619        1914              NaN             NaN   \n",
       "19811274         4298        -999              NaN             NaN   \n",
       "19811275        11265        1997              NaN             NaN   \n",
       "19811276        29775        2001              NaN             NaN   \n",
       "19811277        92271        2001              NaN             NaN   \n",
       "\n",
       "          dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "0                     2.4                NaN              1020.9   \n",
       "1                     2.4                NaN              1020.9   \n",
       "2                     2.4                NaN              1020.9   \n",
       "3                     2.4                NaN              1020.9   \n",
       "4                     2.4                NaN              1020.9   \n",
       "...                   ...                ...                 ...   \n",
       "19811273              NaN                NaN                 NaN   \n",
       "19811274              NaN                NaN                 NaN   \n",
       "19811275              NaN                NaN                 NaN   \n",
       "19811276              NaN                NaN                 NaN   \n",
       "19811277              NaN                NaN                 NaN   \n",
       "\n",
       "          wind_direction  wind_speed  \n",
       "0                  240.0         3.1  \n",
       "1                  240.0         3.1  \n",
       "2                  240.0         3.1  \n",
       "3                  240.0         3.1  \n",
       "4                  240.0         3.1  \n",
       "...                  ...         ...  \n",
       "19811273             NaN         NaN  \n",
       "19811274             NaN         NaN  \n",
       "19811275             NaN         NaN  \n",
       "19811276             NaN         NaN  \n",
       "19811277             NaN         NaN  \n",
       "\n",
       "[19811278 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[\"timestamp\",\"meter_reading\"])\n",
    "\n",
    "# converting meter_reading to y where y=log(meter_reading + 1)\n",
    "y = np.log1p(train[\"meter_reading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log(y_pred+1) - np.log(y_true+1))))\n",
    "\n",
    "rmsle_error = make_scorer(rmsle, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lgbm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LGBMRegressor(),\n",
       "             param_grid={'colsample_bytree': [0.9], 'learning_rate': [0.01],\n",
       "                         'metric': ['rmse'], 'n_estimators': [512, 1024],\n",
       "                         'num_leaves': [32, 64], 'objective': ['regression']},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\" : [0.01],\n",
    "    \"n_estimators\" : [512, 1024],\n",
    "    \"num_leaves\" : [32,64],\n",
    "    \"objective\" : [\"regression\"],\n",
    "    \"metric\" : [\"rmse\"],\n",
    "    \"colsample_bytree\": [0.9],\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "grid = GridSearchCV(lgbm, param_grid, scoring=\"neg_mean_squared_error\", cv=3, return_train_score=True)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([199.72734555, 229.77577527, 348.01061145, 387.6663216 ]),\n",
       " 'std_fit_time': array([4.19531339, 4.42991553, 6.98625899, 5.69784995]),\n",
       " 'mean_score_time': array([ 40.16014163,  53.91560276,  99.09592072, 120.87006418]),\n",
       " 'std_score_time': array([0.67412087, 0.61536504, 1.0521504 , 1.14858308]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.9, 0.9, 0.9, 0.9],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_metric': masked_array(data=['rmse', 'rmse', 'rmse', 'rmse'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[512, 512, 1024, 1024],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_num_leaves': masked_array(data=[32, 64, 32, 64],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_objective': masked_array(data=['regression', 'regression', 'regression', 'regression'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'metric': 'rmse',\n",
       "   'n_estimators': 512,\n",
       "   'num_leaves': 32,\n",
       "   'objective': 'regression'},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'metric': 'rmse',\n",
       "   'n_estimators': 512,\n",
       "   'num_leaves': 64,\n",
       "   'objective': 'regression'},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'metric': 'rmse',\n",
       "   'n_estimators': 1024,\n",
       "   'num_leaves': 32,\n",
       "   'objective': 'regression'},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'learning_rate': 0.01,\n",
       "   'metric': 'rmse',\n",
       "   'n_estimators': 1024,\n",
       "   'num_leaves': 64,\n",
       "   'objective': 'regression'}],\n",
       " 'split0_test_score': array([-2.12901274, -1.90710958, -1.88136797, -1.66172034]),\n",
       " 'split1_test_score': array([-2.17294319, -1.90750017, -1.91489837, -1.66069051]),\n",
       " 'split2_test_score': array([-2.00265015, -1.76763636, -1.79302849, -1.58273675]),\n",
       " 'mean_test_score': array([-2.10153536, -1.8607487 , -1.86309828, -1.6350492 ]),\n",
       " 'std_test_score': array([0.0721858 , 0.06584056, 0.05140301, 0.03699288]),\n",
       " 'rank_test_score': array([4, 2, 3, 1], dtype=int32),\n",
       " 'split0_train_score': array([-1.90402527, -1.55041013, -1.57614252, -1.21476405]),\n",
       " 'split1_train_score': array([-1.81166353, -1.49888656, -1.53597547, -1.2085191 ]),\n",
       " 'split2_train_score': array([-1.89463738, -1.5369901 , -1.58385689, -1.21084578]),\n",
       " 'mean_train_score': array([-1.87010872, -1.52876226, -1.56532496, -1.21137631]),\n",
       " 'std_train_score': array([0.04150433, 0.02182418, 0.02099083, 0.00257694])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9,\n",
       " 'learning_rate': 0.01,\n",
       " 'metric': 'rmse',\n",
       " 'n_estimators': 1024,\n",
       " 'num_leaves': 64,\n",
       " 'objective': 'regression'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['building_id', 'meter', 'DT_M', 'DT_W', 'DT_D', 'DT_hour',\n",
    "       'DT_day_week', 'DT_day_month', 'DT_week_month', 'DT_h_sin', 'DT_h_cos',\n",
    "       'weekend', 'site_id', 'primary_use', 'square_feet', 'year_built',\n",
    "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
    "       'wind_speed']\n",
    "\n",
    "categorical_features = ['building_id', 'meter', 'DT_M', 'DT_W',\n",
    "       'DT_D', 'DT_hour', 'DT_day_week', 'DT_day_month', 'DT_week_month', 'weekend',\n",
    "       'site_id', 'primary_use', 'year_built']\n",
    "\n",
    "train_data = lgb.Dataset(X,label=y, categorical_feature=categorical_features, feature_name=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.730629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3237\n",
      "[LightGBM] [Info] Number of data points in the train set: 19811278, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 4.212522\n",
      "21-02-23-193333lgbm.csv saved!\n",
      "lgbm.pkl saved to disk!\n"
     ]
    }
   ],
   "source": [
    "param= {\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"num_iterations\" : 1024,\n",
    "    \"num_leaves\" : 64,\n",
    "    \"objective\" : \"regression\",\n",
    "    \"metric\" : \"rmse\",\n",
    "    \"colsample_bytree\": 0.9,\n",
    "\n",
    "}\n",
    "\n",
    "lgbm = lgb.train(param, train_data, categorical_feature=categorical_features, feature_name=features)\n",
    "\n",
    "save_submission(lgbm, \"lgbm\")\n",
    "save_model(lgbm,\"lgbm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/model/kaggle/lgbm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                 0\n",
       "meter                       0\n",
       "DT_M                        0\n",
       "DT_W                        0\n",
       "DT_D                        0\n",
       "DT_hour                     0\n",
       "DT_day_week                 0\n",
       "DT_day_month                0\n",
       "DT_week_month               0\n",
       "DT_h_sin                    0\n",
       "DT_h_cos                    0\n",
       "weekend                     0\n",
       "site_id                     0\n",
       "primary_use                 0\n",
       "square_feet                 0\n",
       "year_built                  0\n",
       "air_temperature        107896\n",
       "cloud_coverage        8644205\n",
       "dew_temperature        111378\n",
       "precip_depth_1_hr     3757868\n",
       "sea_level_pressure    1234975\n",
       "wind_direction        1450706\n",
       "wind_speed             155227\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all these are numerical features\n",
    "features_to_impute = [\n",
    "    \"air_temperature\",\n",
    "    \"cloud_coverage\",\n",
    "    \"dew_temperature\",\n",
    "    \"precip_depth_1_hr\",\n",
    "    \"sea_level_pressure\",\n",
    "    \"wind_direction\",\n",
    "    \"wind_speed\"\n",
    "]\n",
    "\n",
    "impute_vals = {}\n",
    "\n",
    "# Median imputation\n",
    "\n",
    "for site_id in range(0,15+1):\n",
    "    site = {}\n",
    "    for feature in features_to_impute:\n",
    "        median = X[X[\"site_id\"]==site_id][feature].median()\n",
    "        median = 0 if np.isnan(median) else median\n",
    "        site.update({feature : median})\n",
    "      \n",
    "    impute_vals.update({site_id : site})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'air_temperature': 25.0,\n",
       "  'cloud_coverage': 4.0,\n",
       "  'dew_temperature': 21.7,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1018.0,\n",
       "  'wind_direction': 120.0,\n",
       "  'wind_speed': 3.1},\n",
       " 1: {'air_temperature': 11.3,\n",
       "  'cloud_coverage': 0.0,\n",
       "  'dew_temperature': 7.8,\n",
       "  'precip_depth_1_hr': 0,\n",
       "  'sea_level_pressure': 1017.6,\n",
       "  'wind_direction': 220.0,\n",
       "  'wind_speed': 3.6},\n",
       " 2: {'air_temperature': 25.6,\n",
       "  'cloud_coverage': 2.0,\n",
       "  'dew_temperature': 3.3,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1011.0,\n",
       "  'wind_direction': 120.0,\n",
       "  'wind_speed': 2.6},\n",
       " 3: {'air_temperature': 15.6,\n",
       "  'cloud_coverage': 4.0,\n",
       "  'dew_temperature': 9.4,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1018.0,\n",
       "  'wind_direction': 190.0,\n",
       "  'wind_speed': 3.6},\n",
       " 4: {'air_temperature': 15.0,\n",
       "  'cloud_coverage': 2.0,\n",
       "  'dew_temperature': 10.6,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1016.7,\n",
       "  'wind_direction': 260.0,\n",
       "  'wind_speed': 3.6},\n",
       " 5: {'air_temperature': 11.0,\n",
       "  'cloud_coverage': 0.0,\n",
       "  'dew_temperature': 8.0,\n",
       "  'precip_depth_1_hr': 0,\n",
       "  'sea_level_pressure': 0,\n",
       "  'wind_direction': 240.0,\n",
       "  'wind_speed': 4.6},\n",
       " 6: {'air_temperature': 16.7,\n",
       "  'cloud_coverage': 0.0,\n",
       "  'dew_temperature': 9.4,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1017.5,\n",
       "  'wind_direction': 150.0,\n",
       "  'wind_speed': 2.1},\n",
       " 7: {'air_temperature': 7.8,\n",
       "  'cloud_coverage': 0,\n",
       "  'dew_temperature': 2.6,\n",
       "  'precip_depth_1_hr': 5.0,\n",
       "  'sea_level_pressure': 1015.2,\n",
       "  'wind_direction': 230.0,\n",
       "  'wind_speed': 3.1},\n",
       " 8: {'air_temperature': 23.9,\n",
       "  'cloud_coverage': 4.0,\n",
       "  'dew_temperature': 18.3,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1018.0,\n",
       "  'wind_direction': 140.0,\n",
       "  'wind_speed': 3.1},\n",
       " 9: {'air_temperature': 22.2,\n",
       "  'cloud_coverage': 0.0,\n",
       "  'dew_temperature': 17.2,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1015.8,\n",
       "  'wind_direction': 120.0,\n",
       "  'wind_speed': 2.1},\n",
       " 10: {'air_temperature': 11.1,\n",
       "  'cloud_coverage': 0.0,\n",
       "  'dew_temperature': 0.0,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1014.5,\n",
       "  'wind_direction': 170.0,\n",
       "  'wind_speed': 3.1},\n",
       " 11: {'air_temperature': 7.5,\n",
       "  'cloud_coverage': 0,\n",
       "  'dew_temperature': 2.3,\n",
       "  'precip_depth_1_hr': 5.0,\n",
       "  'sea_level_pressure': 1015.2,\n",
       "  'wind_direction': 230.0,\n",
       "  'wind_speed': 3.1},\n",
       " 12: {'air_temperature': 9.8,\n",
       "  'cloud_coverage': 7.0,\n",
       "  'dew_temperature': 6.7,\n",
       "  'precip_depth_1_hr': 0,\n",
       "  'sea_level_pressure': 1015.8,\n",
       "  'wind_direction': 230.0,\n",
       "  'wind_speed': 5.0},\n",
       " 13: {'air_temperature': 11.1,\n",
       "  'cloud_coverage': 2.0,\n",
       "  'dew_temperature': 3.9,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1015.9,\n",
       "  'wind_direction': 180.0,\n",
       "  'wind_speed': 4.1},\n",
       " 14: {'air_temperature': 13.3,\n",
       "  'cloud_coverage': 0.0,\n",
       "  'dew_temperature': 6.1,\n",
       "  'precip_depth_1_hr': 0.0,\n",
       "  'sea_level_pressure': 1016.5,\n",
       "  'wind_direction': 210.0,\n",
       "  'wind_speed': 2.6},\n",
       " 15: {'air_temperature': 11.1,\n",
       "  'cloud_coverage': 0.0,\n",
       "  'dew_temperature': 6.7,\n",
       "  'precip_depth_1_hr': -1.0,\n",
       "  'sea_level_pressure': 1017.2,\n",
       "  'wind_direction': 170.0,\n",
       "  'wind_speed': 3.1}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values\n",
    "for site_id in range(0, 15+1):\n",
    "    df = X[X[\"site_id\"]==site_id].fillna(impute_vals[site_id])\n",
    "    X[X[\"site_id\"]==site_id] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id           0\n",
       "meter                 0\n",
       "DT_M                  0\n",
       "DT_W                  0\n",
       "DT_D                  0\n",
       "DT_hour               0\n",
       "DT_day_week           0\n",
       "DT_day_month          0\n",
       "DT_week_month         0\n",
       "DT_h_sin              0\n",
       "DT_h_cos              0\n",
       "weekend               0\n",
       "site_id               0\n",
       "primary_use           0\n",
       "square_feet           0\n",
       "year_built            0\n",
       "air_temperature       0\n",
       "cloud_coverage        0\n",
       "dew_temperature       0\n",
       "precip_depth_1_hr     0\n",
       "sea_level_pressure    0\n",
       "wind_direction        0\n",
       "wind_speed            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null vals after imputation\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling null vals in test data from train data impute vals\n",
    "with open(\"../data/test_featurized.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "for site_id in range(0, 15+1):\n",
    "    df = test[test[\"site_id\"]==site_id].fillna(impute_vals[site_id])\n",
    "    test[test[\"site_id\"]==site_id] = df\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:1211: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SGDRegressor(),\n",
       "             param_grid={'alpha': [0.0001, 0.01, 0.1]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'alpha' :[0.0001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "lin = SGDRegressor()\n",
    "grid = GridSearchCV(lin, param_grid, scoring=\"neg_mean_squared_error\", cv=3)\n",
    "grid.fit(X ,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-02-26-112301_lin.csv saved!\n",
      "linear.pkl saved to disk!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "linear = SGDRegressor(alpha = 0.01, eta0=1e-5, learning_rate=\"constant\")\n",
    "linear.fit(scaler.fit_transform(X) ,y)\n",
    "\n",
    "del X\n",
    "del train\n",
    "del y\n",
    "gc.collect()\n",
    "\n",
    "save_submission(linear, \"_lin\", scaler.transform)\n",
    "save_model(linear,\"linear.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/model/kaggle/lin.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-02-25-181850_dtr.csv saved!\n",
      "dtr.pkl saved to disk!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X, y)\n",
    "\n",
    "del X\n",
    "del train\n",
    "del y\n",
    "gc.collect()\n",
    "\n",
    "save_submission(dtr, \"_dtr\")\n",
    "save_model(dtr,\"dtr.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/model/kaggle/dtr.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada = AdaBoostRegressor(n_estimators = 1000)\n",
    "ada.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada.pkl saved to disk!\n"
     ]
    }
   ],
   "source": [
    "del X\n",
    "del train\n",
    "del y\n",
    "gc.collect()\n",
    "save_model(ada,\"ada.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-02-26-193019_ada.csv saved!\n"
     ]
    }
   ],
   "source": [
    "save_submission(ada, \"_ada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/model/kaggle/ada.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606721/606721 [==============================] - 1877s 3ms/step - loss: 5.0854 - mean_squared_error: 5.0854\n",
      "Epoch 1/4\n",
      "38694/38694 [==============================] - 348s 9ms/step - loss: 4.3686 - mean_squared_error: 4.3686 - val_loss: 4.3637 - val_mean_squared_error: 4.3644\n",
      "Epoch 2/4\n",
      "38694/38694 [==============================] - 340s 9ms/step - loss: 4.3686 - mean_squared_error: 4.3686 - val_loss: 4.3637 - val_mean_squared_error: 4.3644\n",
      "Epoch 3/4\n",
      "38694/38694 [==============================] - 345s 9ms/step - loss: 4.3686 - mean_squared_error: 4.3686 - val_loss: 4.3637 - val_mean_squared_error: 4.3644\n",
      "Epoch 4/4\n",
      "38694/38694 [==============================] - 340s 9ms/step - loss: 4.3686 - mean_squared_error: 4.3686 - val_loss: 4.3638 - val_mean_squared_error: 4.3645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b290977d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.02, random_state=42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Dense(23, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(2, activation='relu'),\n",
    "    Dense(1)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(X, y, epochs=4, callbacks=[tensorboard_callback],batch_size = 512, validation_data=(X_val, y_val), validation_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mlp/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-03-01-181751_mlp.csv saved!\n"
     ]
    }
   ],
   "source": [
    "save_submission(model, \"_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/model/kaggle/mlp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.01, eta0=1e-05, learning_rate='constant')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"ada.pkl\", \"rb\") as f:\n",
    "    ada = pickle.load(f)\n",
    "\n",
    "with open(\"lgbm.pkl\", \"rb\") as f:\n",
    "    lgbm = pickle.load(f)\n",
    "\n",
    "with open(\"linear.pkl\", \"rb\") as f:\n",
    "    linear = pickle.load(f)\n",
    "    \n",
    "def return_train_prediction(model, transform=None):\n",
    "    \n",
    "    if transform is None:\n",
    "        return model.predict(X)\n",
    "    else:\n",
    "        return model.predict(transform(X))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "        \n",
    "base = [ada, lgbm, linear]\n",
    "transforms=[None, None, scaler.transform]\n",
    "meta = SGDRegressor(alpha = 0.01, eta0=1e-5, learning_rate=\"constant\")\n",
    "\n",
    "base_pred = np.zeros((X.shape[0],len(base)), dtype='float')\n",
    "\n",
    "for i,(m,t) in enumerate(zip(base, transforms)):\n",
    "    base_pred[:,i] = return_train_prediction(m, t)\n",
    "\n",
    "meta.fit(base_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta.pkl saved to disk!\n"
     ]
    }
   ],
   "source": [
    "save_model(meta,\"meta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-03-03-140840_meta.csv saved!\n"
     ]
    }
   ],
   "source": [
    "base_pred = np.zeros((test.shape[0],len(base)), dtype='float')\n",
    "    \n",
    "def return_test_prediction(model, transform=None):\n",
    "    \n",
    "    if transform is None:\n",
    "        return model.predict(test.drop(columns=[\"timestamp\",\"row_id\"]))\n",
    "    else:\n",
    "        return model.predict(transform(test.drop(columns=[\"timestamp\",\"row_id\"])))\n",
    "    \n",
    "for i,(m,t) in enumerate(zip(base, transforms)):\n",
    "    base_pred[:,i] = return_test_prediction(m, t)\n",
    "\n",
    "filename = time.strftime(\"%y-%m-%d-%H%M%S\") + \"_meta\" +\".csv\"\n",
    "pd.DataFrame(np.expm1(meta.predict(base_pred)), columns=[\"meter_reading\"]).rename_axis(\"row_id\").to_csv(filename)\n",
    "print(f\"{filename} saved!\")\n",
    "!p7zip $filename >> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/model/kaggle/meta.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
